{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlalchemy\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import random\n",
    "import urllib3\n",
    "from nordvpn_connect import initialize_vpn, rotate_VPN, close_vpn_connection\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ip():\n",
    "    \"\"\" Connects to a nord VPN server.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. Changes server in background.\n",
    "    \"\"\" \n",
    "    settings = initialize_vpn(\"Poland\")  # starts nordvpn and stuff\n",
    "    rotate_VPN(settings)  # actually connect to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def database(url):\n",
    "    \"\"\" Creates context in which engine is created, perform an \n",
    "    action and tear down the connection once finished.\n",
    "    Args:\n",
    "        Connecion URL.\n",
    "    Returns:\n",
    "        Postgres database \n",
    "    \"\"\"\n",
    "    # Create engine\n",
    "    db = sqlalchemy.create_engine(url)\n",
    "    \n",
    "    try: \n",
    "        yield db\n",
    "        \n",
    "    finally:\n",
    "        # Tear down database connection\n",
    "       db.dispose()\n",
    "       # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_page_db():\n",
    "    \"\"\" Check last page in database.\n",
    "    Args:\n",
    "        Connecion URL.\n",
    "    Returns:\n",
    "        Value of the last page added to database.\n",
    "    \"\"\"\n",
    "# set connection\n",
    "    db_string = \"postgresql://postgres:Congitos211!!!@localhost:5432/copart\"\n",
    "\n",
    "    with database(db_string) as db:\n",
    "        # Run the query to fetch the data\n",
    "        result = db.execute(\"SELECT MAX(\\\"Page Number\\\") FROM cars\")\n",
    "        row = result.fetchone() # Select one row\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_null(df):\n",
    "    \"\"\" Check null vales that may appear when scarping is incorrect.\n",
    "    Args:\n",
    "        Dataframe.\n",
    "    Returns:\n",
    "        dataframe without null values and dataframe with null values.\n",
    "    \"\"\"\n",
    "    df_null = df[df.isna().any(axis=1)]\n",
    "    df.dropna(inplace=True)\n",
    "    #if df_null is not None:\n",
    "    #    return df, None\n",
    "    #else:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## create while loop to download scaping data until no more data is avaliable\n",
    "def extract(every_x_load_to_db):\n",
    "    \n",
    "        # check last page in DB\n",
    "        page_number = 4969538\n",
    "        #page_number = read_last_page_db()\n",
    "        #print(last_page)\n",
    "        # monitor how many pages were scraped\n",
    "        records_stored = 0\n",
    "        # creating a final dataframe with all results\n",
    "        dict_list = []\n",
    "        while records_stored < every_x_load_to_db:\n",
    "            try:\n",
    "                if page_number != 'stop':\n",
    "                    soup, page_number = extract_data_and_create_soup(page_number)\n",
    "                    soup_dict = dictionary_with_data_and_features(soup, page_number)\n",
    "                    ## Adding data from soup that is not included in the main soup_dict\n",
    "                    lot_number(soup_dict, soup)\n",
    "                    web_adress(soup_dict)\n",
    "                    car_year(soup_dict, soup)\n",
    "                    car_model(soup_dict, soup)\n",
    "                    location(soup_dict)\n",
    "                    doc_type(soup_dict)\n",
    "                    dict_list.append(soup_dict)\n",
    "                    records_stored = records_stored + 1\n",
    "                    print('Number of records stored in dictionary ' + str(records_stored))\n",
    "                else:\n",
    "                    brak   \n",
    "            except TypeError:\n",
    "                # In case of being blocked change ip\n",
    "                start = time.time()\n",
    "                change_ip()\n",
    "                end = time.time()\n",
    "                elapsed = end - start\n",
    "                print('ip changed')\n",
    "                # If more tha 2min pased from last change consider update as complited.\n",
    "                if elapsed > 120:\n",
    "                    break\n",
    "                print('Update completed, no more new records')\n",
    "        return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    ## Change monetary values to correct format\n",
    "    convert_to_num('Final bid:', df)\n",
    "    convert_to_num('Estimated Repair Cost:', df)\n",
    "    convert_to_num('Estimated Retail Value:', df)\n",
    "    odometer_to_km(df)\n",
    "    convert_date_str_to_date(df)\n",
    "    #engine_type(df)\n",
    "    #cilinders(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    # Load\n",
    "    # Load the data in batch processing to sql database and close connectionn\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl(every_x_load_to_db):\n",
    "    \"\"\" Scraps data from bids-history.com, create a dataframe with auction detail \n",
    "        and load the data into a sql db.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        postgres database \n",
    "    \"\"\"\n",
    "    dictionary = extract(every_x_load_to_db)\n",
    "    df = converting_dictionary_to_dataframe(dictionary)\n",
    "    #df = check_for_null(df)\n",
    "    df = transform(df)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_dictionary_to_dataframe(dictionary):\n",
    "    \"\"\" Converts dictionary to dataframe.\n",
    "    Args:\n",
    "        Takes as agrument dict object.\n",
    "    Returns:\n",
    "        Pandas dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(dictionary,orient='columns')\n",
    "    df = df.set_index(\"Page Number\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_and_create_soup(page_number):\n",
    "    \"\"\" Makes a url request and creates soup.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        bs4.BeautifulSoup object.\n",
    "    \"\"\"    \n",
    "    url = \"https://bids-history.com/lot/\" + str(page_number) + \"/\"\n",
    "    #Get the HMTL text from the homepage.\n",
    "    res = requests.get(url,verify = False)\n",
    "    soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "    # Create soup, if text is 'Not Found' and page_number is high then no more data avaliable \n",
    "    #and stop update. Minimum page number starts from 69600\n",
    "    page_number = page_number + 1\n",
    "    return soup, page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_with_data_and_features(soup, page_number):\n",
    "    \"\"\" Selects features and vales from the soup.\n",
    "    Args:\n",
    "        Takes as agrument object bs4.BeautifulSoup and web page_number.\n",
    "    Returns:\n",
    "        Dictionary with features as keys and data as values. \n",
    "    \"\"\"\n",
    "    items = 0 \n",
    "    Lot_info_key = []\n",
    "    Lot_info_val = []\n",
    "    Lot_info_key.append(\"Page Number\")\n",
    "    Lot_info_val.append(page_number)\n",
    "    for item in soup.select(\".col-6\"):\n",
    "        item = item.text\n",
    "        item = item.replace(\"\\n\", \"\") # Formating word\n",
    "        if items % 2 == 0:\n",
    "            Lot_info_key.append(item)\n",
    "            items += 1\n",
    "        else:\n",
    "            Lot_info_val.append(item)\n",
    "            items += 1\n",
    "    return dict(zip(Lot_info_key, Lot_info_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_num(column_name, df):\n",
    "    \"\"\" Separates data with monetary amounts to 'column_name','currency' columns.\n",
    "    Args:\n",
    "        Takes as agrument column name from dataframe.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[[column_name,'Currency']] = df[column_name].str.split(n=1, expand=True) # Formating price\n",
    "    df[column_name].replace(to_replace=[\",\",\"\\$\"],value='',regex=True, inplace=True)\n",
    "    df[column_name] = df[column_name].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def odometer_to_km(df):\n",
    "    \"\"\" Converts odometer number to KM.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['Odometer:'].replace(to_replace=[\",\",\"mi\"],value='',regex=True, inplace=True)\n",
    "    df['Odometer:'] = (df['Odometer:'].astype(int) * 1.60934).astype(int) # miles to KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_str_to_date(df):\n",
    "    \"\"\" Converts string to python date format.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"    \n",
    "    # Consolidating months abreviation\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('March', 'Mar')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('April', 'Apr')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('June', 'Jun')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('July', 'Jul')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('Sept.', 'Sep')\n",
    "    \n",
    "    # Deleting comas and points\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace(',', '')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('.', '')\n",
    "    \n",
    "    # Converting data to date type\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.upper()\n",
    "    df['Auction Date:'] = [datetime.datetime.strptime(date,'%b %d %Y %H %p') for date in df['Auction Date:']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_type(car_dict):\n",
    "# Converting Engine Type to float number\n",
    "    car_dict['Engine Type:'] = car_dict['Engine Type:'][0].replace(car_dict['Engine Type:'][0][3:],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cilinders(car_dict):\n",
    "# Converting cilinders to  float number\n",
    "    car_dict['Cylinders:'] =int(car_dict['Cylinders:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lot_number(car_dict, soup):\n",
    "    car_dict['Lot number:'] = int(soup.select(\"td a\")[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_adress(car_dict):\n",
    "    car_dict['Web adress'] = str(\"https://bids-history.com/lot/\"+ str(car_dict['Page Number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_year(car_dict, soup):\n",
    "    car_dict['Production year'] = soup.select(\"ol li\")[-1].text[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_model(car_dict, soup):\n",
    "    car_dict['Car Model'] = soup.select(\"ol li\")[-1].text[5:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(car_dict):\n",
    "    car_dict['Location'] = car_dict['Doc Type:'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_type(car_dict):\n",
    "    car_dict['Doc Type:'] =  car_dict['Doc Type:'][5:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sqlalchemy\n",
    "\n",
    "connection_uri = \"postgresql://postgres:Congitos211!!!@localhost:5432/copart\"\n",
    "db_engine_copart = sqlalchemy.create_engine(connection_uri)\n",
    "\n",
    "# Finish the .to_sql() call to write to store.film\n",
    "df.to_sql(\"cars\", con=db_engine_copart,  if_exists=\"replace\")\n",
    "\n",
    "# Run the query to fetch the data\n",
    "pd.read_sql(\"SELECT * FROM cars\", db_engine_copart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_test(every_x_load_to_db):\n",
    "    \"\"\" Scraps data from bids-history.com, create a dataframe with auction detail \n",
    "        and load the data into a sql db.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        postgres database \n",
    "    \"\"\"\n",
    "    dictionary = extract(every_x_load_to_db)\n",
    "    df = converting_dictionary_to_dataframe(dictionary)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_test2(every_x_load_to_db):\n",
    "    \"\"\" Scraps data from bids-history.com, create a dataframe with auction detail \n",
    "        and load the data into a sql db.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        postgres database \n",
    "    \"\"\"\n",
    "    dictionary = extract(every_x_load_to_db)\n",
    "    df = converting_dictionary_to_dataframe(dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records stored in dictionary 1\n",
      "Number of records stored in dictionary 2\n",
      "Number of records stored in dictionary 3\n",
      "Number of records stored in dictionary 4\n",
      "Number of records stored in dictionary 5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d07fa6eb2835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0metl_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-17a18f582e4b>\u001b[0m in \u001b[0;36metl_test\u001b[1;34m(every_x_load_to_db)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpostgres\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevery_x_load_to_db\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverting_dictionary_to_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-86682bb0f05e>\u001b[0m in \u001b[0;36mextract\u001b[1;34m(every_x_load_to_db)\u001b[0m\n\u001b[0;32m     16\u001b[0m                     \u001b[0msoup_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary_with_data_and_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[1;31m## Adding data from soup that is not included in the main soup_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                     \u001b[0mlot_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                     \u001b[0mweb_adress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mcar_year\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-5bee9ff5d845>\u001b[0m in \u001b[0;36mlot_number\u001b[1;34m(car_dict, soup)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlot_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcar_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lot number:'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df = etl_test(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = df.copy()\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = etl_test2(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
