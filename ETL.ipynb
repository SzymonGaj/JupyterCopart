{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import exc\n",
    "import time\n",
    "from time import sleep\n",
    "from contextlib import contextmanager\n",
    "import random\n",
    "import urllib3\n",
    "from nordvpn_connect import initialize_vpn, rotate_VPN, close_vpn_connection\n",
    "from socket import gethostbyname, gaierror\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ip():\n",
    "    \"\"\" Connects to a nord VPN server.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. Changes server in background.\n",
    "    \"\"\" \n",
    "    settings = initialize_vpn(\"Poland\")  # starts nordvpn and stuff\n",
    "    rotate_VPN(settings)  # actually connect to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def database(url):\n",
    "    \"\"\" Creates context in which engine is created, perform an \n",
    "    action and tear down the connection once finished.\n",
    "    Args:\n",
    "        Connecion URL.\n",
    "    Returns:\n",
    "        Postgres database \n",
    "    \"\"\"\n",
    "    # Create engine\n",
    "    db = sa.create_engine(url)\n",
    "    \n",
    "    try: \n",
    "        yield db\n",
    "        \n",
    "    finally:\n",
    "        # Tear down database connection\n",
    "       db.dispose()\n",
    "       # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_last_page_db():\n",
    "    \"\"\" Check last page in database.\n",
    "    Args:\n",
    "        Connecion URL.\n",
    "    Returns:\n",
    "        Value of the last page added to database.\n",
    "    \"\"\"\n",
    "# set connection\n",
    "    db_string = \"postgresql://postgres:Congitos211!!!@localhost:5432/copart\"\n",
    "\n",
    "    with database(db_string) as db:\n",
    "        # Run the query to fetch the data\n",
    "        result = db.execute(\"SELECT MAX(page_number) FROM cars\")\n",
    "        row = result.fetchone() # Select one row\n",
    "        if row[0] == None:\n",
    "            row = 70000\n",
    "            return row\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_null(df):\n",
    "    \"\"\" Check null vales that may appear when scarping is incorrect.\n",
    "    Args:\n",
    "        Dataframe.\n",
    "    Returns:\n",
    "        dataframe without null values and dataframe with null values.\n",
    "    \"\"\"\n",
    "    df_null = df[df.isna().any(axis=1)]\n",
    "    df.dropna(inplace=True)\n",
    "    #if df_null is not None:\n",
    "    #    return df, None\n",
    "    #else:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timed(func):\n",
    "    \"\"\" Decorator for mesuring time of function execution.\n",
    "    Args:\n",
    "        function\n",
    "    Returns:\n",
    "        Executes function and prints elapsed time since start.\n",
    "    \"\"\"\n",
    "    def wrapper():\n",
    "        start = time.time()\n",
    "        result = func()\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        print('extract executed in ' + str(elapsed) + 's')\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test(return_every=12):\n",
    "    while True:\n",
    "            # check last page in DB\n",
    "            page_number = read_last_page_db() + 1\n",
    "            dict_list = []\n",
    "            stored_in_dic = 0\n",
    "            dict_error = {}\n",
    "            while True:\n",
    "                try:\n",
    "                    soup = extract_data_and_create_soup(page_number)\n",
    "                    soup_dict = dictionary_with_data_and_features(soup, page_number)\n",
    "                    ## Adding data from soup that is not included in the soup_dict\n",
    "                    lot_number(soup_dict, soup)\n",
    "                    web_adress(soup_dict)\n",
    "                    car_year(soup_dict, soup)\n",
    "                    car_model(soup_dict, soup)\n",
    "                    dict_list.append(soup_dict)\n",
    "                    page_number = page_number + 1\n",
    "                    stored_in_dic = len(dict_list)\n",
    "                    # Return if number of stored items reach\n",
    "                    if stored_in_dic >= return_every:\n",
    "                        df = converting_dictionary_to_dataframe(dict_list)\n",
    "                        return df\n",
    "                        \n",
    "                except IndexError as e:\n",
    "                    print(\"OOPS!! Index error\")\n",
    "                    print(str(e))\n",
    "                    print('Number of records stored ' + str(stored_in_dic))\n",
    "                    print('Current page_number ' + str(page_number))\n",
    "                    if page_number not in dict_error:\n",
    "                        dict_error[page_number] = 1\n",
    "                    else:\n",
    "                        dict_error[page_number] += 1\n",
    "                    if dict_error[page_number] > 2:\n",
    "                        page_number = page_number + 1\n",
    "                        print('Modified page_number ' + str(page_number))\n",
    "                    print(dict_error)\n",
    "                    print('Changing ip adress')\n",
    "                    change_ip()\n",
    "                    continue\n",
    "                except requests.ConnectionError as e:\n",
    "                    print(\"OOPS!! Connection Error. Make sure you are connected to Internet. Technical Details given below.\\n\")\n",
    "                    print(str(e))            \n",
    "                    change_ip()\n",
    "                    continue\n",
    "                except requests.Timeout as e:\n",
    "                    print(\"OOPS!! Timeout Error\")\n",
    "                    print(str(e))\n",
    "                    change_ip()\n",
    "                    continue\n",
    "                except requests.RequestException as e:\n",
    "                    print(\"OOPS!! General Error\")\n",
    "                    print(str(e))\n",
    "                    change_ip()\n",
    "                    continue\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"Someone closed the program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \"\"\" Scraps data from bids-history.com until stoped by server, change ip adress and\n",
    "    create a dataframe with scraped data.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    # check last page in DB\n",
    "    page_number = read_last_page_db() + 1\n",
    "    #page_number = 70346\n",
    "    dict_list = []\n",
    "    while True:\n",
    "        try:\n",
    "            soup = extract_data_and_create_soup(page_number)\n",
    "            soup_dict = dictionary_with_data_and_features(soup, page_number)\n",
    "            ## Adding data from soup that is not included in the soup_dict\n",
    "            lot_number(soup_dict, soup)\n",
    "            web_adress(soup_dict)\n",
    "            car_year(soup_dict, soup)\n",
    "            car_model(soup_dict, soup)\n",
    "            dict_list.append(soup_dict)\n",
    "            page_number = page_number + 1\n",
    "        except IndexError:\n",
    "            break\n",
    "            \n",
    "    if len(dict_list) > 0:\n",
    "        print('Number of records stored ' + str(len(dict_list)))\n",
    "        print('Current page_number ' + str(page_number))\n",
    "        df = converting_dictionary_to_dataframe(dict_list)\n",
    "        return df\n",
    "    else:\n",
    "        print('No df to return, check if page exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    \"\"\" Transforms strings to numeric values.\n",
    "    Args:\n",
    "        Dataframe from extract step.\n",
    "    Returns:\n",
    "        Modified dataframe.\n",
    "    \"\"\"\n",
    "    #print(df)\n",
    "    ## Drop records with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "    ## Change monetary values to correct format\n",
    "    convert_to_num('Final bid:', df)\n",
    "    convert_to_num('Estimated Repair Cost:', df)\n",
    "    convert_to_num('Estimated Retail Value:', df)\n",
    "    location(df)\n",
    "    doc_type(df)\n",
    "    odometer_to_km(df)\n",
    "    convert_date_str_to_date(df)\n",
    "    engine_type(df)\n",
    "    cilinders(df)\n",
    "    production_year(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df):\n",
    "    # Load\n",
    "    # Load the data in batch processing to sql database and close connectionn\n",
    "    rename_colums(df)\n",
    "    load_to_sql_db(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed\n",
    "def etl():\n",
    "    \"\"\" Scraps data from bids-history.com, create a dataframe with auction detail \n",
    "        and load the data into a sql db.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        postgres database \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        df = extract_test()\n",
    "        df = transform(df)\n",
    "        load(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_dictionary_to_dataframe(dictionary):\n",
    "    \"\"\" Converts dictionary to dataframe.\n",
    "    Args:\n",
    "        Takes as agrument dict object.\n",
    "    Returns:\n",
    "        Pandas dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(dictionary,orient='columns')\n",
    "    df = df.set_index(\"Page Number\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_and_create_soup(page_number):\n",
    "    \"\"\" Makes a url request and creates soup.\n",
    "    Args:\n",
    "        None.\n",
    "    Returns:\n",
    "        bs4.BeautifulSoup object.\n",
    "    \"\"\"    \n",
    "    url = \"https://bids-history.com/lot/\" + str(page_number) + \"/\"\n",
    "    #Get the HMTL text from the homepage.\n",
    "    res = requests.get(url,verify = False, allow_redirects=False)\n",
    "    soup = bs4.BeautifulSoup(res.text,'lxml')\n",
    "    # Create soup, if text is 'Not Found' and page_number is high then no more data avaliable \n",
    "    #and stop update. Minimum page number starts from 69600\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_with_data_and_features(soup, page_number):\n",
    "    \"\"\" Selects features and vales from the soup.\n",
    "    Args:\n",
    "        Takes as agrument object bs4.BeautifulSoup and web page_number.\n",
    "    Returns:\n",
    "        Dictionary with features as keys and data as values. \n",
    "    \"\"\"\n",
    "    items = 0 \n",
    "    Lot_info_key = []\n",
    "    Lot_info_val = []\n",
    "    Lot_info_key.append(\"Page Number\")\n",
    "    Lot_info_val.append(page_number)\n",
    "    for item in soup.select(\".col-6\"):\n",
    "        item = item.text\n",
    "        item = item.replace(\"\\n\", \"\") # Formating word\n",
    "        if items % 2 == 0:\n",
    "            Lot_info_key.append(item)\n",
    "            items += 1\n",
    "        else:\n",
    "            Lot_info_val.append(item)\n",
    "            items += 1\n",
    "    return dict(zip(Lot_info_key, Lot_info_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_num(column_name, df):\n",
    "    \"\"\" Separates data with monetary amounts to 'column_name','currency' columns.\n",
    "    Args:\n",
    "        Takes as agrument column name from dataframe.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"\n",
    "    df[[column_name,'Currency']] = df[column_name].str.split(n=1, expand=True) # Formating price\n",
    "    df[column_name].replace(to_replace=[\",\",\"\\$\"],value='',regex=True, inplace=True)\n",
    "    df[column_name] = df[column_name].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def odometer_to_km(df):\n",
    "    \"\"\" Converts odometer number to KM.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    df['Odometer:'].replace(to_replace=[\",\",\"mi\"],value='',regex=True, inplace=True)\n",
    "    df['Odometer:'] = (df['Odometer:'].astype(int) * 1.60934).astype(int) # miles to KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_str_to_date(df):\n",
    "    \"\"\" Converts string to python date format.\n",
    "    Args:\n",
    "        No args.\n",
    "    Returns:\n",
    "        Nothing. It converts values inplace in the dataframe.\n",
    "    \"\"\"    \n",
    "    #print(df['Auction Date:'])\n",
    "    # Consolidating months abreviation\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('March', 'Mar')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('April', 'Apr')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('June', 'Jun')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('July', 'Jul')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('Sept.', 'Sep')\n",
    "    \n",
    "    # Exceptions\n",
    "    ## In case of NOON change to 12 am\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('noon', '12 a.m.')\n",
    "\n",
    "    ## In case of data fomated as: May 7, 2019, 7:55 a.m.\n",
    "    df['Auction Date:'] .replace(to_replace=\":[0-9][0-9]\", value=\"\", regex=True, inplace=True)\n",
    "    \n",
    "    # Deleting comas and points\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace(',', '')\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.replace('.', '')\n",
    "    \n",
    "    # Converting data to date type\n",
    "    df['Auction Date:'] = df['Auction Date:'].str.upper()\n",
    "    df['Auction Date:'] = [datetime.datetime.strptime(date,'%b %d %Y %H %p') for date in df['Auction Date:']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine_type(car_dict):\n",
    "    def test_completnes(x):\n",
    "        \"Full string with engine data has at least 6 characters\"\n",
    "        if len(x) > 1:\n",
    "            return x\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    series  = pd.Series(car_dict['Engine Type:']).map(lambda x: x[:4])\n",
    "    series  = series.map(test_completnes)\n",
    "    series = series.str.strip()\n",
    "    series = series.str.replace('L', '')\n",
    "    series = series.astype(float)\n",
    "    car_dict['Engine Type:'] =  series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cilinders(car_dict):\n",
    "    car_dict['Cylinders:'] =  pd.Series(car_dict['Cylinders:']).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lot_number(car_dict, soup):\n",
    "    car_dict['Lot number:'] = int(soup.select(\"td a\")[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_adress(car_dict):\n",
    "    car_dict['Web adress'] = str(\"https://bids-history.com/lot/\"+ str(car_dict['Page Number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_year(car_dict, soup):\n",
    "    car_dict['Production year'] = soup.select(\"ol li\")[-1].text[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_model(car_dict, soup):\n",
    "    car_dict['Car Model'] = soup.select(\"ol li\")[-1].text[5:]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be corrected form dict to df\n",
    "def location(car_dict):\n",
    "    car_dict['Location'] = pd.Series(car_dict['Doc Type:']).map(lambda x: x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be corrected form dict to df\n",
    "def doc_type(car_dict):\n",
    "    car_dict['Doc Type:'] =  pd.Series(car_dict['Doc Type:']).map(lambda x: x[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def production_year(car_dict):     \n",
    "    car_dict['Production year'] =  pd.to_numeric(car_dict['Production year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_colums(df):\n",
    "    # rename index\n",
    "    df.index.rename(\"page_number\", inplace=True)\n",
    "    # rename columns\n",
    "    df.rename({'Final bid:':\"final_bid\",\n",
    "                 'Doc Type:':\"doc_type\",\n",
    "                 'Odometer:':\"odometer\",\n",
    "                 'Highlights:':\"highlights\",\n",
    "                 'Primary Damage:':\"primary_damage\",\n",
    "                 'Secondary Damage:':\"secondary_damage\",\n",
    "                 'Estimated Repair Cost:':\"estimated_repair_cost\",\n",
    "                 'Estimated Retail Value:':\"estimated_retail_value\",\n",
    "                 'VIN:':\"vin\",\n",
    "                 'Auction Date:':\"auction_date\",\n",
    "                 'Body Style:':\"body_style\",\n",
    "                 'Engine Type:':\"engine_type\",\n",
    "                 'Cylinders:':\"cylinders\",\n",
    "                 'Transmission:':\"transmission\",\n",
    "                 'Drive:':\"drive\",\n",
    "                 'Fuel:':\"fuel\",  \n",
    "                 'Lot number:':\"lot_number\",\n",
    "                 'Web adress':\"web_adress\",\n",
    "                 'Production year':\"production_year\",\n",
    "                 'Car Model':\"car_model\",\n",
    "                 \"Currency\":\"currency\",\n",
    "                 'Location':\"location\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load to db\n",
    "\n",
    "def load_to_sql_db(df):\n",
    "    try:\n",
    "        user=\"postgres\",\n",
    "        password=\"Congitos211!!!\",\n",
    "        host=\"localhost\",\n",
    "        #port=\"5432\",\n",
    "        database=\"copart\"\n",
    "        connection_uri = \"postgresql://postgres:Congitos211!!!@localhost:5432/copart\"\n",
    "        #connection_uri = f\"postgresql://{user}:{password}@{host}:{str(port)}/{database}\"\n",
    "\n",
    "        db_engine_copart = sa.create_engine(connection_uri)\n",
    "        # Finish the .to_sql() call to write to store.film\n",
    "        df.to_sql(\"cars\", con=db_engine_copart,  if_exists=\"append\")\n",
    "        print(\"Records stored\")\n",
    "        # pd.read_sql(\"SELECT * FROM cars\", db_engine_copart)\n",
    "    except exc.IntegrityError:\n",
    "        print(\"Exception. Records already stored\")\n",
    "    finally:\n",
    "        db_engine_copart.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_sql_db():\n",
    "\n",
    "    user=\"postgres\"\n",
    "    password=\"Congitos211!!!\"\n",
    "    host=\"localhost\"\n",
    "    port=\"5432\"\n",
    "    database=\"copart\"\n",
    "\n",
    "    connection_uri = f\"postgresql://{user}:{password}@{host}:{str(port)}/{database}\"\n",
    "    #connection_uri = \"postgresql://postgres:Congitos211!!!@localhost:5432/copart\"\n",
    "\n",
    "    db_engine_copart = sa.create_engine(connection_uri)\n",
    "\n",
    "    pd.read_sql(\"SELECT * FROM cars\", db_engine_copart)\n",
    "    print(\"Records loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
